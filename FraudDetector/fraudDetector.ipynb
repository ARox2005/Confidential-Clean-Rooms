{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55c80290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Setup and Dependencies\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "print(\"Dependencies loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab5cd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "-> Loaded and combined 2 broker datasets. Total trades: 5000\n",
      "-> Loaded 2500 social media records.\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Load and Combine Datasets\n",
    "#\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Identify paths for brokers and social media platforms from the injected dictionary\n",
    "# broker_paths = [path for owner, path in client_paths.items() if owner.startswith('Broker')]\n",
    "# social_paths = [path for owner, path in client_paths.items() if owner.startswith('Social')]\n",
    "\n",
    "broker_paths = [clientA_path, clientB_path]\n",
    "social_paths = [ClientC_path]\n",
    "\n",
    "# Load and concatenate all broker datasets into a single DataFrame\n",
    "broker_dfs = [pd.read_csv(path, parse_dates=['timestamp']) for path in broker_paths]\n",
    "trading_df = pd.concat(broker_dfs, ignore_index=True)\n",
    "print(f\"-> Loaded and combined {len(broker_dfs)} broker datasets. Total trades: {len(trading_df)}\")\n",
    "\n",
    "# Load the social media dataset\n",
    "social_df = pd.read_csv(social_paths[0], parse_dates=['timestamp'])\n",
    "print(f\"-> Loaded {len(social_df)} social media records.\")\n",
    "alerts = []  # Initialize alerts list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43f496ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 1: Detecting trading anomalies...\n",
      "-> Found 25 anomalous trading events across all brokers.\n",
      "Suspicious Trade: Trader user-k5m6 anomalously traded 3673600 shares of GME on 2021-01-22.\n",
      "Suspicious Trade: Trader user-c8e1 anomalously traded 1926780 shares of GME on 2021-01-24.\n",
      "Suspicious Trade: Trader cluster-9f4e anomalously traded 4106088 shares of GME on 2021-01-26.\n",
      "Suspicious Trade: Trader user-c8e1 anomalously traded 2272995 shares of GME on 2021-01-27.\n",
      "Suspicious Trade: Trader user-f6a9 anomalously traded 2276064 shares of GME on 2021-01-27.\n",
      "Suspicious Trade: Trader user-g2h7 anomalously traded 2187360 shares of GME on 2021-01-27.\n",
      "Suspicious Trade: Trader cluster-3b8a anomalously traded 1975824 shares of GME on 2021-02-10.\n",
      "Suspicious Trade: Trader cluster-1c5d anomalously traded 3228520 shares of GME on 2021-02-12.\n",
      "Suspicious Trade: Trader cluster-1c5d anomalously traded 1740078 shares of GME on 2021-02-13.\n",
      "Suspicious Trade: Trader cluster-9f4e anomalously traded 3271743 shares of GME on 2021-02-13.\n",
      "Suspicious Trade: Trader cluster-1c5d anomalously traded 3952116 shares of GME on 2021-02-15.\n",
      "Suspicious Trade: Trader user-h3i8 anomalously traded 2607556 shares of GME on 2021-01-20.\n",
      "Suspicious Trade: Trader user-d9f2 anomalously traded 3171136 shares of GME on 2021-01-20.\n",
      "Suspicious Trade: Trader user-e1g3 anomalously traded 2715727 shares of GME on 2021-01-21.\n",
      "Suspicious Trade: Trader cluster-3b8a anomalously traded 1970952 shares of GME on 2021-01-21.\n",
      "Suspicious Trade: Trader cluster-1c5d anomalously traded 2094732 shares of GME on 2021-01-26.\n",
      "Suspicious Trade: Trader user-2c4e anomalously traded 2077842 shares of GME on 2021-01-26.\n",
      "Suspicious Trade: Trader user-h3i8 anomalously traded 2051910 shares of GME on 2021-01-28.\n",
      "Suspicious Trade: Trader cluster-9f4e anomalously traded 1922682 shares of GME on 2021-02-01.\n",
      "Suspicious Trade: Trader cluster-1c5d anomalously traded 1909557 shares of GME on 2021-02-03.\n",
      "Suspicious Trade: Trader cluster-3b8a anomalously traded 3810042 shares of GME on 2021-02-04.\n",
      "Suspicious Trade: Trader cluster-7a2b anomalously traded 3798567 shares of GME on 2021-02-07.\n",
      "Suspicious Trade: Trader cluster-9f4e anomalously traded 2690905 shares of GME on 2021-02-08.\n",
      "Suspicious Trade: Trader cluster-1c5d anomalously traded 2357538 shares of GME on 2021-02-11.\n",
      "Suspicious Trade: Trader cluster-1c5d anomalously traded 2451533 shares of GME on 2021-02-14.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPhase 1: Detecting trading anomalies...\")\n",
    "# This model identifies trades that are outliers compared to the rest of the data.\n",
    "# We assume about 1% of trades might be anomalous for this simulation.\n",
    "anomaly_model = IsolationForest(contamination=0.005, random_state=42)\n",
    "features = ['trade_volume', 'order_book_depth']\n",
    "\n",
    "# The model's 'fit_predict' returns -1 for anomalies and 1 for normal trades.\n",
    "predictions = anomaly_model.fit_predict(trading_df[features])\n",
    "trading_df['is_anomaly'] = (predictions == -1)\n",
    "print(f\"-> Found {trading_df['is_anomaly'].sum()} anomalous trading events across all brokers.\")\n",
    "alerts.append(\"Trading Anomaly Detected:\")\n",
    "for row in trading_df[trading_df['is_anomaly']].itertuples():\n",
    "    alert = f\"Suspicious Trade: Trader {row.anonymized_trader_id} anomalously traded {row.trade_volume} shares of {row.stock_symbol} on {row.timestamp.date()}.\"\n",
    "    alerts.append(alert)\n",
    "    print(alert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72399e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 2: Detecting social media hype...\n",
      "-> Found 18 social media hype events.\n",
      "Hype Spike: Stock GME saw activity 144016 on 2021-01-20.\n",
      "Hype Spike: Stock GME saw activity 99576 on 2021-01-21.\n",
      "Hype Spike: Stock GME saw activity 105066 on 2021-01-22.\n",
      "Hype Spike: Stock GME saw activity 105906 on 2021-01-23.\n",
      "Hype Spike: Stock GME saw activity 144696 on 2021-01-25.\n",
      "Hype Spike: Stock GME saw activity 138240 on 2021-01-30.\n",
      "Hype Spike: Stock GME saw activity 102130 on 2021-01-31.\n",
      "Hype Spike: Stock GME saw activity 193491 on 2021-02-02.\n",
      "Hype Spike: Stock GME saw activity 124704 on 2021-02-04.\n",
      "Hype Spike: Stock GME saw activity 138816 on 2021-02-04.\n",
      "Hype Spike: Stock GME saw activity 45321 on 2021-02-04.\n",
      "Hype Spike: Stock GME saw activity 86778 on 2021-02-04.\n",
      "Hype Spike: Stock GME saw activity 89782 on 2021-02-09.\n",
      "Hype Spike: Stock GME saw activity 96060 on 2021-02-10.\n",
      "Hype Spike: Stock GME saw activity 96888 on 2021-02-11.\n",
      "Hype Spike: Stock GME saw activity 85962 on 2021-02-12.\n",
      "Hype Spike: Stock GME saw activity 45198 on 2021-02-13.\n",
      "Hype Spike: Stock GME saw activity 63707 on 2021-02-14.\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Phase 2 - Social Media Hype Detection\n",
    "#\n",
    "print(\"\\nPhase 2: Detecting social media hype...\")\n",
    "# We'll define \"hype\" as a burst of activity significantly higher than the average for a given stock.\n",
    "# A Z-score approach (measuring standard deviations from the mean) is effective here.\n",
    "social_df['mean_activity'] = social_df.groupby('stock_symbol')['activity_level'].transform('mean')\n",
    "social_df['std_activity'] = social_df.groupby('stock_symbol')['activity_level'].transform('std')\n",
    "\n",
    "# A hype event is when activity is more than 3 standard deviations above the average.\n",
    "social_df['is_hype'] = social_df['activity_level'] > (social_df['mean_activity'] + 3 * social_df['std_activity'])\n",
    "print(f\"-> Found {social_df['is_hype'].sum()} social media hype events.\")\n",
    "alerts.append(f\"Social Media Hype Detected:\")\n",
    "for row in social_df[social_df['is_hype']].itertuples():\n",
    "    alert = f\"Hype Spike: Stock {row.stock_symbol} saw activity {row.activity_level} on {row.timestamp.date()}.\"\n",
    "    alerts.append(alert)\n",
    "    print(alert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a3bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 3: Correlating social hype with trading anomalies...\n",
      "-> Generated 1 high-confidence pump-and-dump alerts.\n",
      "Alert: Anomalous trade of 3171136 shares for stock GME by Broker user-d9f2 within 2 hours of hype spike (activity=144016.0).\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Phase 3 - Correlation Engine\n",
    "#\n",
    "print(\"\\nPhase 3: Correlating social hype with trading anomalies...\")\n",
    "# This is the core of the model. We check if a trading anomaly occurred\n",
    "# shortly after a social media hype event for the same stock.\n",
    "\n",
    "# We sort both datasets by time to prepare for the time-sensitive merge.\n",
    "trading_df.sort_values('timestamp', inplace=True)\n",
    "social_df.sort_values('timestamp', inplace=True)\n",
    "\n",
    "# pd.merge_asof is perfect for this. For each trade, it finds the most recent\n",
    "# social media signal within the last 15 minutes.\n",
    "merged_df = pd.merge_asof(\n",
    "    trading_df,\n",
    "    social_df,\n",
    "    on='timestamp',\n",
    "    by='stock_symbol',\n",
    "    direction='forward', # Looks for the social signal *before* the trade.\n",
    "    tolerance=pd.Timedelta('120min')\n",
    ")\n",
    "\n",
    "# A final alert is generated only if an anomalous trade is linked to a recent hype event.\n",
    "alerts_df = merged_df[(merged_df['is_anomaly'] == True) & (merged_df['is_hype'] == True)].copy()\n",
    "print(f\"-> Generated {len(alerts_df)} high-confidence pump-and-dump alerts.\")\n",
    "for _, alert in alerts_df.iterrows():\n",
    "    alerts.append(f\"Alert: Anomalous trade of {alert['trade_volume']} shares \"\n",
    "        f\"for stock {alert['stock_symbol']} by Broker {alert['anonymized_trader_id']} \"\n",
    "        f\"within 2 hours of hype spike (activity={alert['activity_level']}).\")\n",
    "    print(\n",
    "        f\"Alert: Anomalous trade of {alert['trade_volume']} shares \"\n",
    "        f\"for stock {alert['stock_symbol']} by Broker {alert['anonymized_trader_id']} \"\n",
    "        f\"within 2 hours of hype spike (activity={alert['activity_level']}).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e872822d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving results...\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Save the Result\n",
    "#\n",
    "print(\"\\nSaving results...\")\n",
    "# The executor expects a file named 'result.*' to upload.\n",
    "alerts_json = {\"alerts\": alerts}\n",
    "with open(\"result.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(alerts_json, f, indent=4)\n",
    "\n",
    "\n",
    "# if not alerts_df.empty:\n",
    "#     output_columns = [\n",
    "#         'timestamp',\n",
    "#         'stock_symbol',\n",
    "#         'trade_volume',\n",
    "#         'activity_level',\n",
    "#         'mean_activity'\n",
    "#     ]\n",
    "#     # Ensure all selected columns exist before saving\n",
    "#     final_alerts = alerts_df[[col for col in output_columns if col in alerts_df.columns]]\n",
    "#     final_alerts.to_csv('result.csv', index=False)\n",
    "#     print(\"-> Alerts saved to result.csv\")\n",
    "# else:\n",
    "#     # Create an empty result file if no alerts were found.\n",
    "#     pd.DataFrame(columns=['timestamp', 'stock_symbol', 'message']).to_csv('result.csv', index=False)\n",
    "#     print(\"-> No alerts generated. An empty result.csv has been created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
